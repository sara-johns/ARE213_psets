---
title: "ARE 213 Problem Set 2B"
author: "Becky Cardinali, Yuen Ho, Sara Johns, and Jacob Lefler"
date: "Due 11/16/2020"
header-includes: 
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \usepackage{amsmath}
output: pdf_document
fig_caption: yes
geometry: margin=1.5cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#======================
# Section 0: Set Up
#======================

# Clear workspace
rm(list = ls())

# Load packages
library(pacman)
library(zoo)
library(haven)
p_load(data.table, dplyr, foreign, readstata13, tidyr, xtable, ggplot2, binom, glmnet, stats, FNN, fastDummies, fixest, parallel, plm, lmtest, fixest, Synth)

# set seed for replication
set.seed(1995)
# for mclapply
core.num <- (detectCores()/2)
# Directory 
# base_directory <- "/Users/sarajohns/Desktop/ARE213_psets/"
base_directory <- "/Users/beckycardinali/Desktop/ARE213_psets/"
# base_directory <- "/Users/yuen/Documents/GitHub/ARE213_psets/"
# base_directory <- "C:\\Users\\jacob\\Documents\\GitHub\\ARE213_psets\\"

# read data
traffic <- as.data.table(read_dta(paste0(base_directory, "traffic_safety2.dta")))

```

# Question 1

We first estimate an event study specification.

(a) First determine the minimum and maximum event time values that you can estimate in this data set. Code up a separate event time indicator for each possible value of event time in the data set. Estimate an event study regression using all the event time indicators. What happens?

The data set contains data for each year in $[1981, 2003]$. Therefore, the minimum number of event time values we can estimate in this data set is 23 $(2003-1981+1)$, which would be the case where all states are treated in the same year, all states are treated during all years in the data set, or all states are untreated during all years in the data set. 

The maximum event time value we can estimate in this data set is 47?? $(2003-1981+1)*2$, which would be the case where at least one state was treated for the entire sample (event time 1 to 23) and at least one state was never treated during the sample (event time -23 to -1) (23 + 23 + 1 for event time 0)

We have a single treated state $(s = 1$ when the state has a primary seat belt law) and a single control state $(s = 0$ when a state does not have a primary seat belt law). So for an event study regression using all the event time indicators, we will estimate the regression: 
$$Y_{ist} = \alpha + \sum_{j=-T_0}^{T-T_0} \tau_j D_{jst} + \gamma_s + \delta_t + \epsilon_{st} + u_{ist}$$
where $T_0$ is the period just prior to treatment, and $D_{jst}$ is an indicator function for period $t$ falling $j$ periods after $T_0$ in the treated state (i.e., $\textbf{1}(t-T_0 = j)*\textbf{1}(s=1)$), so index $j$ is "event time."

```{r, include = TRUE}
# Becky's notes to be deleted later
# what if the primary seat belt law was taken away? i don't think it would show up in event time indicator, but that would make interpretation weird
# how to code event time for places that never get treated? doesn't matter because they won't show up in the summation since D=0 always
# how to code event time for places that were treated throughout the sample? it's luckily not the case in our sample, but might affect the max values part of this question
# work out case for completely treated? think it won't work above because of second for loop with i in 0:1
# doing logs like in pset 1, what about controls, 1+ for constant?
# since the sum of the event time indicators is collinear with the treated state's fixed effect. ???
# do you need dummy_cols if you use fixef?


# separate event time indicator for each possible value of event time in the data set

# create event time variable
traffic <- traffic[, event_time := NA]

# iterate through all states (this includes state 99)
for(s in unique(traffic$state)){

  # data frame for just state s
  temp <- subset(traffic, state == s)
  # make sure it's in ascending order by year
  temp <- temp[order(year), ]

  # find the row # and year corresponding to the first occurrence of primary == 1 in the dataframe for just that state
  row_of_first_occ <- match(1, temp$primary)
  first_treated_year <- traffic[match(1, temp$primary), year]
  
  # case where a state was never treated in the sample (row_of_first_occ == NA)
  if(is.na(row_of_first_occ)){
    k <- -1
    for(i in 23:1){
       # year 2003 corresponds to event time = -1, year 2002 corresponds to event time = -2, etc.
      setDT(traffic)[, event_time := ifelse(state == s & year == (2004 + k), k, event_time)]
      k <- k - 1
    }
  }
  
  # case where a state was treated in the sample (row_of_first_occ > 1)
  # no cases of a state being treated during the entire sample
  else{
    # for the first year with primary == 1, make event time = 0
    setDT(traffic)[, event_time := ifelse(state == s & year == first_treated_year, 0, event_time)]

    k <- 1
    for(i in (row_of_first_occ+1):23){
      # year after event time 0 corresponds to event time 1, 2 years after event time 0 corresponds to event time 2, etc.
      setDT(traffic)[, event_time := ifelse(state == s & year == (first_treated_year + k), k, event_time)]
      k <- k + 1
      }

    k <- -1
    for(i in (row_of_first_occ-1):1){
      # year before event time 0 corresponds to event time -1, 2 years before event time 0 corresponds to event time -2, etc.
      setDT(traffic)[, event_time := ifelse(state == s & year == (first_treated_year + k), k, event_time)]
      k <- k - 1
      }
  }
}

# make separate event time indicator for each possible value of event time in the data set + state and year dummies
traffic <- traffic[,dummy_cols(traffic, select_columns = c("year", "state", "event_time"))]

# create y variable
traffic[, ln_fat_pc := log((fatalities/population))]

# event study regression using all the event time indicators
# this isn't working because event_time_-23 and all the negative number ones are weird
# even when when I just included event_time_2*primary, it removed event_time_2*primary because of collinearity
es1 <- feols(ln_fat_pc ~ 1 + `event_time_-23`*primary + `event_time_-22`*primary + `event_time_-21`*primary +  
               `event_time_-20`*primary + `event_time_-19`*primary + `event_time_-18`*primary + `event_time_-17`*primary +
               `event_time_-16`*primary + `event_time_-15`*primary + `event_time_-14`*primary +
               `event_time_-13`*primary + `event_time_-12`*primary + `event_time_-11`*primary +
               `event_time_-10`*primary + `event_time_-9`*primary + `event_time_-8`*primary +
               `event_time_-7`*primary + `event_time_-6`*primary + `event_time_-5`*primary +
               `event_time_-4`*primary + `event_time_-3`*primary + `event_time_-2`*primary +
               `event_time_-1`*primary + event_time_0*primary + event_time_1*primary + 
               event_time_2*primary + event_time_3*primary + event_time_4*primary +
               event_time_5*primary + event_time_6*primary + event_time_7*primary +
               event_time_8*primary + event_time_9*primary + event_time_10*primary +
               event_time_11*primary + event_time_12*primary + event_time_13*primary +
               event_time_14*primary + event_time_15*primary + event_time_16*primary +
               event_time_17*primary + event_time_18*primary + event_time_19*primary, fixef = c("year", "state"), traffic)





```

When we estimate an event study regression using all the event time indicators, the following message pops up: "The variable 'event_time' has been removed because of collinearity." ? This makes sense because the sum in $Y_{ist} = \alpha + \sum_{j=-T_0}^{T-T_0} \tau_j D_{jst} + \gamma_s + \delta_t + \epsilon_{st} + u_{ist}$ contains $T$ dummy variables, which fully saturates event time and leads to the dummy variable trap since the sum of the event time indicators is collinear with the treated state's fixed effect. 

(b) Estimate another event study regression using all the event time indicators save one that you choose to omit. Generate a plot of the event study coefficients. 

```{r, include = TRUE}

# omit event_time -1
es2 <- feols(ln_fat_pc ~ 1 + `event_time_-23`*primary + `event_time_-22`*primary + `event_time_-21`*primary +  
               `event_time_-20`*primary + `event_time_-19`*primary + `event_time_-18`*primary + `event_time_-17`*primary +
               `event_time_-16`*primary + `event_time_-15`*primary + `event_time_-14`*primary +
               `event_time_-13`*primary + `event_time_-12`*primary + `event_time_-11`*primary +
               `event_time_-10`*primary + `event_time_-9`*primary + `event_time_-8`*primary +
               `event_time_-7`*primary + `event_time_-6`*primary + `event_time_-5`*primary +
               `event_time_-4`*primary + `event_time_-3`*primary + `event_time_-2`*primary +
               event_time_0*primary + event_time_1*primary + 
               event_time_2*primary + event_time_3*primary + event_time_4*primary +
               event_time_5*primary + event_time_6*primary + event_time_7*primary +
               event_time_8*primary + event_time_9*primary + event_time_10*primary +
               event_time_11*primary + event_time_12*primary + event_time_13*primary +
               event_time_14*primary + event_time_15*primary + event_time_16*primary +
               event_time_17*primary + event_time_18*primary + event_time_19*primary, 
             fixef = c("year", "state"), traffic)

```


# Question 2

We now apply the synthetic control methods from Abadie et al (2010).

(a)

i. Compare the average pre-period log traffic fatalities per capita of the TU site to that of the average of all the “control” states. Next, graph the pre-period log traffic fatalities by year for the pre-period for both the TU and the average of the control group. Interpret.

```{r}
treatment_year <- 1986 # TU has primary=1 starting in 1986
traffic_pre <- traffic[year<1986,]
TU_fatal_pre <- traffic_pre[state==99,fatalities] # treated unit
CU_fatal_pre <- traffic_pre[state!=99 && state!=09 && state!=19 && state!=35&& state!=48,fatalities] # control units



```








