---
title: "ARE 213 Problem Set 1A"
author: "Becky Cardinali, Yuen Ho, Sara Johns, and Jacob Lefler"
date: "Due 09/25/2020"
header-includes: 
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \usepackage{amsmath}
output: pdf_document
fig_caption: yes
geometry: margin=1.5cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#======================
# Section 0: Set Up
#======================

# Clear workspace
rm(list = ls())

# Load packages
library(pacman)
p_load(data.table, dplyr, foreign, readstata13, tidyr, xtable, ggplot2, binom)

# Directory 
base_directory <- "/Users/sarajohns/Desktop/ARE213_psets/"
# base_directory <- "/Users/beckycardinali/Desktop/ARE213_psets/"

# read data
mom_dt <- read.dta(paste0(base_directory, "ps1.dta"))

```

## Section 1

1. *Before getting started with the data work, first consider the table from Snow (1855) reproduced in the lecture notes ("Snow's Table IX"). The table reports only means.

(a) Develop an approximate 95% confidence interval for "Deaths per 10,000 Houses" for Southwark and Vaxhall customers. Develop another 95% CI for the same quantity for Lambeth. Do the confidence intervals overlap?

Note that that we're estimating $p$ for a binomial distribution since deaths per 10,000 houses is the same as deaths per person (of course, scaled by persons per 10,000 households). Are we really dealing with a binomial distribution? Probably not, but it might not be a bad approximation if we think contaminated water is distributed randomly across space-time (so one person's probability exposure and subsequent death is the same and independent of another person's). Also, not everyone is equally susceptible to the virus (some have a higher $p$ than others), but our estimate of $p$ can be interpreted as an average $p$.

There are various ways to construct a confidence interval for an estimated binomial distribution. We use three different methods, all of which provide very similar estimates. The confidence intervals do not overlap.

```{r, include = TRUE}
# Southwark and Vauxhall
binom.confint(1263, 40046, method=c("asymptotic", "wilson", "agresti-coull"), type="central")

# Lambeth
binom.confint(98, 26107, method=c("asymptotic", "wilson", "agresti-coull"), type="central")
```

(b) Discuss either formally or intuitively the critical assumption that underlies your confidence intervals. Give a 2 or 3 sentence quote from Snow's description (reproduced in Freedman (1991)) that supports this assumption.

To be confident that it is the choice of water company that is causing the difference in $p$ and not some other factor, we need to be sure that there are not systematic differences between those who get their water from Southwark and Vauxhall and those who get it from Lambeth. John Snow argues that the two groups of people are comparable: "both rich and poor, both large houses and small" etc. In that case, we are reasonably certain that the difference in water company is what causes the difference in mortality risk.

## Section 2

We now move to some analysis of real data. The data portions of Problem Sets 1a and 1b are based heavily on the paper Almond, Chay, and Lee (2005), and problem sets from Ken Chay and John DiNardo based on some of the data used in the paper. The goal of this assignment is to examine the research question: what is the causal effect of maternal smoking during pregnancy on infant birthweight and other infant health outcomes. The data for the problem set is an extract of all births from the 1993 National Natality Detail Files for Pennsylvania. Each observation represents an infant-mother match. The data in Stata format can be downloaded from the bCourses website. There should be 48 variables in the data and, after you are finished with the cleaning steps desribed below, 114,610 observations. 

The data here are "real" and quite imperfect, which will help simulate the unpleasantness of real world data work. Unlike the real world where you will confront this bleak situation largely alone, I will provide you with some hints for working your way through the raw data. You can download part of the codebook for the data to help you figure out the relevant variables.

2. The first order of business is to go through the code book, decide on the relevant variables, and process the data. This involves several steps: 

(a) Fix missing values. In the data set several variables take on a value of, say, 9999 if missing. We have already checked for missing observations for about 2/3 of the variables. The remaining variables need to be checked and are the last 15 in the variables list (i.e. from 'cardiac' to 'wgain'). Refer to the codebook for missing value codes. Produce an analysis data set that drops any observations with missing values. 

```{r, include = TRUE}
# According to the codebook, for the following medical risk factor variables, 8 corresponds to 
# "Factor not on certificate" and 9 corresponds to "Factor not classifiable": cardiac, lung, 
# diabetes, herpes, chyper, phyper, pre4000, preterm

med_risk_factors <- c('cardiac', 'lung', 'diabetes', 'herpes', 'chyper', 'phyper', 'pre4000', 'preterm')

for (var in med_risk_factors){
  mom_dt[var] <- replace(mom_dt[var], which(mom_dt[var] == 8, arr.ind = TRUE), NA)
  mom_dt[var] <- replace(mom_dt[var], which(mom_dt[var] == 9, arr.ind = TRUE), NA)
}

# Below, arr.ind = TRUE returns the indices at which the row equals a certain value

# According to the codebook, for tobacco, 9 corresponds to "Unknown or not stated"
mom_dt$tobacco <- replace(mom_dt$tobacco, which(mom_dt$tobacco == 9, arr.ind = TRUE), NA)

# According to the codebook, for cigar, 99 corresponds to "Unknown or not stated"
mom_dt$cigar <- replace(mom_dt$cigar, which(mom_dt$cigar == 99, arr.ind = TRUE), NA)

# According to the codebook, for cigar6, 6 corresponds to "Unknown or not stated"
mom_dt$cigar6 <- replace(mom_dt$cigar6, which(mom_dt$cigar6 == 6, arr.ind = TRUE), NA)

# According to the codebook, for alcohol, 9 corresponds to "Unknown or not stated"
mom_dt$alcohol <- replace(mom_dt$alcohol, which(mom_dt$alcohol == 9, arr.ind = TRUE), NA)

# According to the codebook, for drink, 99 corresponds to "Unknown or not stated"
mom_dt$drink <- replace(mom_dt$drink, which(mom_dt$drink == 99, arr.ind = TRUE), NA)

# According to the codebook, for drink5, 5 corresponds to "Unknown or not stated"
mom_dt$drink5 <- replace(mom_dt$drink5, which(mom_dt$drink5 == 5, arr.ind = TRUE), NA)

# According to the codebook, for wgain (assuming that's wtgain in codebook), 
# 99 corresponds to "Unknown or not stated"
mom_dt$wgain <- replace(mom_dt$wgain, which(mom_dt$wgain == 99, arr.ind = TRUE), NA)

# Make indicator for missing, will drop after comparison
setDT(mom_dt)
mom_dt[, miss := ifelse(complete.cases(mom_dt), 0, 1)]

# Now mom_dt contains 114,610 observations instead of the original 120,461

```

(b) If this were a real research project you would want to consider other approaches to missing data besides termination with extreme prejudice. What observations do you have to drop because of missing data? Might this affect your results? Do the data appear to be missing completely at random? How might you assess whether the data appear to be missing at random?

We know from the last problem set that if the data are missing at random then dropping them should not affect our results of the effect of smoking on birth weight. However, if the missing data is correlated with the treatment (smoking) or the outcome (birth weight) then it could bias our results. From the table below, it does appear that there are differences in the missing and nonmissing data. For example, the mothers in the missing data are younger, less educated, less likely to be married, have more previous children, received less prenatal care, have a shorter time since the last birth, have a lower gestation period, and have lower birth weight. As discussed in the last problem set, we could formally assess whether the data is missing at random by regressing an indicator for the missing variable on the treatment. 

In the table, we calculate the mean and standard deviation of the variables for the missing and nonmissing data. We also calculate the t-stat: 

$$ t = \frac{Mean_m - Mean_{nm}}{\sqrt{\frac{Var_m}{n_m} + \frac{Var_{nm}}{n_{nm}}}}$$ 

the degrees of freedom:

$$ \frac{\frac{Var_m}{n_m} + \frac{Var_{nm}}{n_{nm}}}{\frac{(\frac{Var_m}{n_m})^2}{n_m-1} + \frac{(\frac{Var_{nm}}{n_{nm}})^2}{n_{nm}-1}}$$
and the p-value which is the probability that the t-statistic achieves the value calculated.

```{r, include = TRUE}

# Compare missing to non missing
compare_dt <- transpose(mom_dt[,lapply(.SD, mean, na.rm=TRUE), .SDcols = c(6, 9:18, 20, 22, 25:30, 33:43, 45:46, 48), by = miss])
compare_dt <- cbind(compare_dt, transpose(mom_dt[,lapply(.SD, sd, na.rm=TRUE), .SDcols = c(6, 9:18, 20, 22, 25:30, 33:43, 45:46, 48), by = miss]))
colnames(compare_dt) <- c("Nonmiss means", "Miss means", "Nonmiss sd", "Miss sd")
compare_dt <- compare_dt[2:34,]
compare_dt[, Variable := c("Mother age", "Mother educ", "Marital status", "Prenatal adequacy", "Number living child",
           "Number dead or living child", "Total live birth or terminations", "Birth order", "Month prenatal began",
           "Number prenatal visits", "Time since last birth", "Father age", "Father educ", "Gestation", "Child sex",
           "Birth weight", "Number born", "One min Apgar", "Five min Apgar", "Anemia", "Cardiac disease",
           "Lung disease", "Diabetes", "Herpes", "Chron. hypertension", "Preg. hypertension", "Previous heavy birth",
           "Previous preterm", "Tobacco use", "Number cigarettes", "Alcohol use", "Number drinks", "Weight gain")]

formulas <- paste("mom_dt$", names(mom_dt)[c(6, 9:18, 20, 22, 25:30, 33:43, 45:46, 48)], "~ mom_dt$miss")
t_test <- t(sapply(formulas, function(f) {      
  res <- t.test(as.formula(f))
  c(res$statistic, p.value=res$p.value)      
}))

colnames(t_test) <- c("t-stat", "p-value")

compare_dt <- cbind(compare_dt, t_test)
compare_dt[, Difference := `Nonmiss means` - `Miss means`]

setcolorder(compare_dt, c("Variable", "Nonmiss means", "Nonmiss sd", "Miss means", "Miss sd", "Difference", "t-stat", "p-value"))

mom_dt <- na.omit(mom_dt)
```

```{r, include=TRUE, results = 'asis'}

print(xtable(compare_dt, caption = 'Difference in Means Missing v Nonmissing', digits = 2), 
      include.rownames = FALSE, size = "small", comment = FALSE)

```

(c) Produce a summary table describing the final analysis data set.

We create a summary table similar to the table in b, but this time we compare the means of smokers vs non-smokers. To see means/standard deviations for the entire dataset, refer to the nonmissing data columns of part b. We will discuss the differences between the groups in 3b.

```{r, include = TRUE}
# Recode to binary 0/1 treatment
# tobacco is 1: yes, tobacco use during pregnancy and 2: no tobacco use during pregnancy
mom_dt[, tobacco := ifelse(tobacco==2, 0, 1)]

# Compare smoker to nonsmoker
summary_dt <- transpose(mom_dt[,lapply(.SD, mean, na.rm=TRUE), .SDcols = c(6, 9:18, 20, 22, 25:30, 33:41, 43, 45:46, 48), by = tobacco])
summary_dt <- cbind(summary_dt, transpose(mom_dt[,lapply(.SD, sd, na.rm=TRUE), .SDcols = c(6, 9:18, 20, 22, 25:30, 33:41, 43, 45:46, 48), by = tobacco]))
colnames(summary_dt) <- c("Nonsmoker means", "Smoker means", "Nonsmoker sd", "Smoker sd")
summary_dt <- summary_dt[2:33,]
summary_dt[, Variable := c("Mother age", "Mother educ", "Marital status", "Prenatal adequacy", "Number living child",
           "Number dead or living child", "Total live birth or terminations", "Birth order", "Month prenatal began",
           "Number prenatal visits", "Time since last birth", "Father age", "Father educ", "Gestation", "Child sex",
           "Birth weight", "Number born", "One min Apgar", "Five min Apgar", "Anemia", "Cardiac disease",
           "Lung disease", "Diabetes", "Herpes", "Chron. hypertension", "Preg. hypertension", "Previous heavy birth",
           "Previous preterm", "Number cigarettes", "Alcohol use", "Number drinks", "Weight gain")]

formulas <- paste("mom_dt$", names(mom_dt)[c(6, 9:18, 20, 22, 25:30, 33:41, 43, 45:46, 48)], "~ mom_dt$tobacco")
t_test <- t(sapply(formulas, function(f) {      
  res <- t.test(as.formula(f))
  c(res$statistic, p.value=res$p.value)      
}))

colnames(t_test) <- c("t-stat", "p-value")

summary_dt <- cbind(summary_dt, t_test)
summary_dt[, Difference := `Nonsmoker means` - `Smoker means`]

setcolorder(summary_dt, c("Variable", "Nonsmoker means", "Nonsmoker sd", "Smoker means", "Smoker sd", "Difference", "t-stat", "p-value"))

```

```{r, include=TRUE, results = 'asis'}

print(xtable(summary_dt, caption = 'Difference in Means Smoker v Nonsmoker', digits = 2), 
      include.rownames = FALSE, size = "small", comment = FALSE)

```


\newpage

3. The next part of the assignment is to try to estimate the "causal" effect of maternal smoking during pregnancy on infant birth weight. Let's start out using techniques that are familiar, and think about whether they are likely to work in this context. Answer the following questions. 

(a) Compute the mean difference in APGAR scores (both five and one minute versions) as well as birthweight by smoking status.
```{r, include = TRUE}
# According to the codebook, omaps is the one minute APGAR score and fmaps is the five minute APGAR score
# Both are a score from 0-10 
# dbrwt (assuming that corresponds to dbirwt in codebook) is birthweight in grams

smoker <- subset(mom_dt, mom_dt$tobacco == 1)
nonsmoker <- subset(mom_dt, mom_dt$tobacco == 0)

# Mean difference in one minute APGAR score by smoking status
mean_diff_1min_apgar <- mean(smoker$omaps) - mean(nonsmoker$omaps)
print(mean_diff_1min_apgar)

# Mean difference in five minute APGAR score by smoking status
mean_diff_5min_apgar <- mean(smoker$fmaps) - mean(nonsmoker$fmaps)
print(mean_diff_5min_apgar)

# Mean difference in birthweight by smoking status
mean_diff_birthweight <- mean(smoker$dbrwt) - mean(nonsmoker$dbrwt)
print(mean_diff_birthweight)

```
